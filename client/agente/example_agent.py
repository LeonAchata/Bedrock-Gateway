"""Ejemplo completo de uso del nodo LLM con LangGraph.

Este archivo muestra c√≥mo integrar el nodo de consulta LLM
en un grafo LangGraph real con m√∫ltiples nodos y flujo condicional.
"""

import asyncio
import os
from typing import Literal
from llm_node import (
    AgentState,
    llm_consultation_node,
    create_llm_node_for_model,
    quick_query
)

try:
    from langgraph.graph import StateGraph, END
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    print("‚ö†Ô∏è  LangGraph no instalado. Ejecuta: pip install langgraph")


# ==================== EJEMPLO 1: CONSULTA SIMPLE ====================

async def example_simple_query():
    """Ejemplo m√°s simple: una pregunta r√°pida."""
    print("\n" + "="*60)
    print("EJEMPLO 1: Consulta Simple")
    print("="*60)
    
    response = await quick_query(
        model="nova-lite",
        prompt="¬øCu√°l es la capital de Per√∫?"
    )
    
    print(f"\nü§ñ Respuesta: {response}\n")


# ==================== EJEMPLO 2: AGENTE CON UN NODO ====================

async def example_single_node_agent():
    """Ejemplo de grafo con un solo nodo LLM."""
    print("\n" + "="*60)
    print("EJEMPLO 2: Agente de Un Solo Nodo")
    print("="*60)
    
    # Crear grafo
    workflow = StateGraph(AgentState)
    workflow.add_node("llm", llm_consultation_node)
    workflow.set_entry_point("llm")
    workflow.add_edge("llm", END)
    
    app = workflow.compile()
    
    # Ejecutar
    result = await app.ainvoke({
        "messages": [
            {"role": "user", "content": "Resume en 2 l√≠neas qu√© es AWS Bedrock"}
        ],
        "model": "nova-pro",
        "temperature": 0.7,
        "max_tokens": 200
    })
    
    print(f"\nü§ñ Modelo: {result['model']}")
    print(f"üìä Tokens: {result['usage']['total_tokens']}")
    print(f"üí∞ Costo: ${result['cost_usd']:.6f}")
    print(f"\nüí¨ Respuesta:\n{result['response']}\n")


# ==================== EJEMPLO 3: AGENTE MULTI-NODO ====================

async def router_node(state: AgentState) -> AgentState:
    """Nodo que decide qu√© modelo usar seg√∫n la tarea."""
    user_message = state["messages"][-1]["content"].lower()
    
    # Decidir modelo seg√∫n keywords
    if "c√≥digo" in user_message or "python" in user_message:
        model = "claude-3-5-sonnet"  # Claude es mejor para c√≥digo
        print("üîÄ Router: Detectado c√≥digo ‚Üí usando Claude")
    elif "r√°pido" in user_message or "simple" in user_message:
        model = "nova-lite"  # Nova Lite es m√°s r√°pido y barato
        print("üîÄ Router: Consulta simple ‚Üí usando Nova Lite")
    else:
        model = "nova-pro"  # Nova Pro para general purpose
        print("üîÄ Router: Consulta general ‚Üí usando Nova Pro")
    
    return {**state, "model": model}


async def example_multi_node_agent():
    """Ejemplo de grafo con m√∫ltiples nodos y routing."""
    print("\n" + "="*60)
    print("EJEMPLO 3: Agente Multi-Nodo con Router")
    print("="*60)
    
    # Crear grafo
    workflow = StateGraph(AgentState)
    
    # A√±adir nodos
    workflow.add_node("router", router_node)
    workflow.add_node("llm", llm_consultation_node)
    
    # Conectar flujo
    workflow.set_entry_point("router")
    workflow.add_edge("router", "llm")
    workflow.add_edge("llm", END)
    
    app = workflow.compile()
    
    # Test 1: Pregunta de c√≥digo
    print("\nüìù Test 1: Pregunta sobre c√≥digo")
    result1 = await app.ainvoke({
        "messages": [
            {"role": "user", "content": "Escribe un c√≥digo Python para ordenar una lista"}
        ],
        "temperature": 0.5,
        "max_tokens": 300
    })
    print(f"‚úÖ Modelo usado: {result1['model']}")
    print(f"üí¨ Respuesta:\n{result1['response'][:150]}...\n")
    
    # Test 2: Pregunta simple
    print("üìù Test 2: Pregunta r√°pida")
    result2 = await app.ainvoke({
        "messages": [
            {"role": "user", "content": "Dame una respuesta simple: ¬øcu√°nto es 5+5?"}
        ],
        "temperature": 0.3,
        "max_tokens": 100
    })
    print(f"‚úÖ Modelo usado: {result2['model']}")
    print(f"üí¨ Respuesta: {result2['response']}\n")


# ==================== EJEMPLO 4: CONVERSACI√ìN MULTI-TURNO ====================

async def example_conversation():
    """Ejemplo de conversaci√≥n con m√∫ltiples turnos."""
    print("\n" + "="*60)
    print("EJEMPLO 4: Conversaci√≥n Multi-Turno")
    print("="*60)
    
    # Crear grafo simple
    workflow = StateGraph(AgentState)
    workflow.add_node("llm", llm_consultation_node)
    workflow.set_entry_point("llm")
    workflow.add_edge("llm", END)
    
    app = workflow.compile()
    
    # Estado inicial
    state = {
        "messages": [],
        "model": "nova-pro",
        "temperature": 0.7,
        "max_tokens": 300
    }
    
    # Turno 1
    print("\nüë§ Usuario: Hola, soy Juan")
    state["messages"].append({"role": "user", "content": "Hola, soy Juan"})
    result = await app.ainvoke(state)
    print(f"ü§ñ Asistente: {result['response']}")
    state = result
    
    # Turno 2
    print("\nüë§ Usuario: ¬øCu√°l es mi nombre?")
    state["messages"].append({"role": "user", "content": "¬øCu√°l es mi nombre?"})
    result = await app.ainvoke(state)
    print(f"ü§ñ Asistente: {result['response']}")
    state = result
    
    # Turno 3
    print("\nüë§ Usuario: Recomi√©ndame un libro sobre IA")
    state["messages"].append({"role": "user", "content": "Recomi√©ndame un libro sobre IA"})
    result = await app.ainvoke(state)
    print(f"ü§ñ Asistente: {result['response']}")
    
    print(f"\nüìä Total tokens usados: {result['usage']['total_tokens']}")
    print(f"üí∞ Costo total: ${result['cost_usd']:.6f}\n")


# ==================== EJEMPLO 5: MODELOS ESPEC√çFICOS ====================

async def example_specialized_agents():
    """Ejemplo con nodos especializados para modelos espec√≠ficos."""
    print("\n" + "="*60)
    print("EJEMPLO 5: Agentes Especializados")
    print("="*60)
    
    # Crear nodos especializados
    claude_node = create_llm_node_for_model("claude-3-5-sonnet")
    nova_node = create_llm_node_for_model("nova-pro")
    
    # Test Claude (mejor para c√≥digo)
    print("\nüß† Claude Sonnet (experto en c√≥digo):")
    workflow_claude = StateGraph(AgentState)
    workflow_claude.add_node("claude", claude_node)
    workflow_claude.set_entry_point("claude")
    workflow_claude.add_edge("claude", END)
    app_claude = workflow_claude.compile()
    
    result_claude = await app_claude.ainvoke({
        "messages": [
            {"role": "user", "content": "Explica qu√© es un decorador en Python"}
        ],
        "temperature": 0.5,
        "max_tokens": 300
    })
    print(f"üí¨ {result_claude['response'][:200]}...")
    
    # Test Nova (mejor para general purpose)
    print("\n‚ö° Nova Pro (general purpose):")
    workflow_nova = StateGraph(AgentState)
    workflow_nova.add_node("nova", nova_node)
    workflow_nova.set_entry_point("nova")
    workflow_nova.add_edge("nova", END)
    app_nova = workflow_nova.compile()
    
    result_nova = await app_nova.ainvoke({
        "messages": [
            {"role": "user", "content": "¬øCu√°les son los pa√≠ses de Am√©rica del Sur?"}
        ],
        "temperature": 0.3,
        "max_tokens": 200
    })
    print(f"üí¨ {result_nova['response']}\n")


# ==================== MAIN ====================

async def main():
    """Ejecutar todos los ejemplos."""
    
    if not LANGGRAPH_AVAILABLE:
        print("‚ùå LangGraph no est√° instalado.")
        print("Instala con: pip install langgraph")
        return
    
    print("\n" + "="*60)
    print("üöÄ EJEMPLOS DE USO - BEDROCK GATEWAY + LANGGRAPH")
    print("="*60)
    print("\n‚öôÔ∏è  Configuraci√≥n:")
    print(f"   AWS Region: {os.getenv('AWS_REGION', 'us-east-1')}")
    print(f"   Gateway: Python MCP Server (stdio)")
    
    try:
        # Ejecutar ejemplos
        await example_simple_query()
        await example_single_node_agent()
        await example_multi_node_agent()
        await example_conversation()
        await example_specialized_agents()
        
        print("\n" + "="*60)
        print("‚úÖ Todos los ejemplos completados exitosamente")
        print("="*60 + "\n")
        
    except Exception as e:
        print(f"\n‚ùå Error ejecutando ejemplos: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # Configurar encoding UTF-8 para Windows
    import sys
    if sys.platform == "win32":
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    # Asegurar que AWS credentials est√©n configuradas
    if not os.getenv("AWS_ACCESS_KEY_ID"):
        print("\nWARNING: AWS_ACCESS_KEY_ID no configurada")
        print("Configura tus credentials AWS antes de ejecutar:\n")
        print("  export AWS_ACCESS_KEY_ID=your_key")
        print("  export AWS_SECRET_ACCESS_KEY=your_secret")
        print("  export AWS_REGION=us-east-1\n")
    
    # Ejecutar
    asyncio.run(main())
